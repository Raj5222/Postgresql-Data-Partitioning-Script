# ğŸš€ PostgreSQL Partitioning Automation
# 1. ğŸ“˜ Introduction

The **PostgreSQL Partitioning Automation Suite** is a complete solution for converting large,
single-table datasets into a **2-level LIST â†’ LIST partitioning architecture**.

This solution is built for:

- Multi-tenant SaaS platforms  
- IOT / device-driven datasets  
- High-ingest logging tables  
- Historical archiving systems  
- Systems suffering from table bloat or slow queries  

The script ensures:

- ğŸ” **Zero data loss**  
- âš™ï¸ **Automatic schema cloning**  
- ğŸ **High-speed migrations**  
- ğŸ›¡ **Full rollback safety**  
- ğŸ§© **Multi-table batch support**

# 2. âš™ï¸ Key Features

### âœ” Zero Data Loss
- Uses atomic SQL transactions
- Performs final row-count verification
- Backup tables are preserved until migration completes

### âœ” Two-Level Partitioning
```
Level 1 â†’ LIST(customer_id)
Level 2 â†’ LIST(bucket_id)
```

### âœ” Automatic Bucket Splitting
- Each bucket stores up to *N* rows (example: 100,000)
- Prevents oversized partitions
- Ensures efficient VACUUM, ANALYZE, and indexing

### âœ” Schema & Index Replication
- Exact schema cloning using pg_catalog introspection
- Auto-patching unique indexes to include partition keys
- Recreates GIN/B-Tree indexes safely on parent

### âœ” Global Rollback System
- Any failure triggers a **global restoration**
- Drops partially-created parent tables
- Renames backup tables back to original names

### âœ” Performance-First Design
- Disables statement timeout  
- Bulk migration uses window functions for optimal bucket calculation  
- Pre-creates partitions to avoid runtime locking

# 3. ğŸ“ System Architecture (ASCII Diagram)

```
Original Table
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   original_table_backup   â”‚â—€â”€â”€â”€ (Preserved for rollback)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Partitioned Parent      â”‚
â”‚   (same name as original) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â–¼                                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L1 Partition: KEY = 708       â”‚         â”‚ L1 Partition: KEY = 999       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                          â”‚
        â–¼                                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L2 Partition: bucket_id = 0    â”‚   â”‚ L2 Partition: bucket_id = 0    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L2 Partition: bucket_id = 1    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

# 4. ğŸ”‘ Primary Key Strategy (Triple-Key Model)

| Column        | Purpose                                    |
|---------------|--------------------------------------------|
| `cmd_id`      | Original unique identifier                 |
| `customer_id` | Required for Level 1 partition routing     |
| `bucket_id`   | Required for Level 2 bucket distribution   |

> PostgreSQL requires **all partitioning columns** to be included in the PK.

# 5. ğŸ› ï¸ Setup & Configuration

### 5.1 Database Configuration
```
DB_HOST="localhost"
DB_PORT="5432"
DB_NAME="0830tero_archive"
DB_USER="postgres"
DB_PASS="0206"
```

### 5.2 Migration Targets
```
declare -a MIGRATION_TARGETS=(
    "custom_module_data : customer_id : 100000"
    "custom_module_equipment_map : cm_id : 10000"
)
```

| Parameter         | Meaning                                                   |
|------------------|-----------------------------------------------------------|
| Table Name       | The target table to be partitioned                        |
| Partition Column | Used for Level 1 LIST partitioning                        |
| Row Limit        | Max rows per bucket (Level 2)                              |


# 6. ğŸ§­ Execution Workflow

### 6.1 Run the Script
```
bash data_partation.sh
```

### 6.2 Detailed Step Flow

```
Step 1 â†’ Validate configuration
Step 2 â†’ Create infrastructure (trigger, tracker)
Step 3 â†’ Backup original table
Step 4 â†’ Create partitioned parent table
Step 5 â†’ Pre-create partitions (L1 & L2)
Step 6 â†’ Clone indexes
Step 7 â†’ Bulk data migration (per customer_id)
Step 8 â†’ Enable routing trigger
Step 9 â†’ Row count verification
Step 10 â†’ VACUUM ANALYZE
```

# 7. ğŸ§ª Real-Time Audit Logging (Sample Output)

```
[SQL] >>> STEP: Copying Data...
[SQL] + PROGRESS: Key 708 | Rows Copied: 100000 | bucket_id: 0 
[SQL] + PROGRESS: Key 708 | Rows Copied: 20000  | bucket_id: 1 
[SQL] + PROGRESS: Key 999 | Rows Copied: 5000   | bucket_id: 0 
```

Logs rotate per partition key and show:

- Row count  
- Assigned bucket
  
# 8. ğŸ”„ Rollback System

### Trigger Conditions:
- Script interruption  
- SQL exception  
- Permission issues  
- Any non-zero exit code  

### Rollback Flow (ASCII Diagram)

```
Error Occurs
     â”‚
     â–¼
Rollback Triggered
     â”‚
     â–¼
Drop partitioned parent table
     â”‚
     â–¼
Rename table_backup â†’ original_name
     â”‚
     â–¼
Backup preserved even if rename fails
```

> Every table in `MIGRATION_TARGETS` is restored automatically.

# 9. ğŸ” Postâ€‘Migration Verification Steps

### 9.1 Check structure
```
\d+ custom_module_data
```

### 9.2 Validate row counts
```
SELECT count(*) FROM custom_module_data;
SELECT count(*) FROM custom_module_data_backup;
```

### 9.3 Check bucket partitions
```
SELECT relname 
FROM pg_class 
WHERE relname LIKE 'custom_module_data_%_bucket_id_%';
```

# 10. ğŸ“Œ Best Practices

- Run during low-traffic window  
- Ensure partition key is NOT NULL  
- Keep backup tables for 7+ days  
- Validate row count carefully  
- Monitor disk usage  
- Test on staging before production  

# 11. ğŸ¯ Conclusion

This tool provides:

- Safe migration  
- Zero-downtime capability  
- High-performance bucket splitting  
- Full rollback  
- Multi-table batching  
- Trigger-based routing  

It is suitable for **enterprise workloads**, **SaaS platforms**, and **massive datasets**.
